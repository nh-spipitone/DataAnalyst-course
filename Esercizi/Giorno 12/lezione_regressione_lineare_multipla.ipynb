{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e513a006",
   "metadata": {},
   "source": [
    "# ğŸ“Š Lezione: Regressione Lineare Multipla per la Previsione delle Performance Studenti\n",
    "\n",
    "## ğŸ¯ Obiettivi della Lezione\n",
    "\n",
    "In questa lezione imparerete:\n",
    "- **Cos'Ã¨ la Regressione Lineare Multipla** e quando utilizzarla\n",
    "- Come **esplorare e preparare i dati** per il machine learning\n",
    "- Come **costruire e valutare** un modello predittivo\n",
    "- Come **interpretare i risultati** e l'importanza delle variabili\n",
    "- Le **migliori pratiche** per progetti di Data Science\n",
    "\n",
    "## ğŸ“‹ Caso di Studio\n",
    "\n",
    "**Problema**: Prevedere l'indice di performance degli studenti (Performance Index) basandosi su:\n",
    "- â° Ore di studio\n",
    "- ğŸ“š Punteggi precedenti  \n",
    "- ğŸƒâ€â™‚ï¸ AttivitÃ  extracurriculari\n",
    "- ğŸ˜´ Ore di sonno\n",
    "- ğŸ“ Numero di test di pratica\n",
    "\n",
    "**Tipo di Problema**: Regressione (previsione di valori continui)\n",
    "**Algoritmo**: Regressione Lineare Multipla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d2667e",
   "metadata": {},
   "source": [
    "## ğŸ“š Sezione 1: Importazione delle Librerie\n",
    "\n",
    "Prima di iniziare qualsiasi progetto di Data Science, dobbiamo importare le librerie necessarie. Ogni libreria ha un ruolo specifico:\n",
    "\n",
    "- **pandas**: Manipolazione e analisi dei dati (DataFrame, lettura CSV, ecc.)\n",
    "- **numpy**: Calcoli numerici e operazioni su array\n",
    "- **matplotlib**: Creazione di grafici e visualizzazioni\n",
    "- **seaborn**: Visualizzazioni statistiche avanzate e piÃ¹ eleganti\n",
    "- **sklearn**: Machine Learning (modelli, preprocessing, metriche, ecc.)\n",
    "\n",
    "> ğŸ’¡ **Tip**: Ãˆ una buona pratica importare tutte le librerie all'inizio del progetto per avere una visione chiara delle dipendenze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ee3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerie per manipolazione dati\n",
    "import pandas as pd           # Analisi e manipolazione dati strutturati\n",
    "import numpy as np           # Calcoli numerici e operazioni matematiche\n",
    "\n",
    "# Librerie per visualizzazione\n",
    "import matplotlib.pyplot as plt  # Creazione di grafici base\n",
    "import seaborn as sns           # Visualizzazioni statistiche avanzate\n",
    "\n",
    "# Librerie per Machine Learning\n",
    "from sklearn.model_selection import train_test_split  # Divisione dataset train/test\n",
    "from sklearn.compose import ColumnTransformer         # Preprocessing colonne diverse\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler  # Encoding e scaling\n",
    "from sklearn.pipeline import Pipeline                 # Creazione pipeline ML\n",
    "from sklearn.linear_model import LinearRegression     # Modello di regressione lineare\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error  # Metriche\n",
    "\n",
    "# Configurazione per grafici piÃ¹ belli\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… Tutte le librerie importate con successo!\")\n",
    "print(\"Ora siamo pronti per iniziare l'analisi dei dati.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e55b67",
   "metadata": {},
   "source": [
    "## ğŸ” Sezione 2: Caricamento e Esplorazione Iniziale dei Dati\n",
    "\n",
    "**PerchÃ© Ã¨ importante l'esplorazione iniziale?**\n",
    "- ğŸ“Š Comprendere la **struttura** e **dimensioni** del dataset\n",
    "- ğŸ” Identificare **valori mancanti** o **anomalie**\n",
    "- ğŸ“ˆ Avere una **prima impressione** sui dati\n",
    "- ğŸ§ Verificare che il dataset sia **corretto** e **completo**\n",
    "\n",
    "### Step dell'esplorazione:\n",
    "1. **Caricamento** del dataset\n",
    "2. **Dimensioni** del dataset (righe Ã— colonne)\n",
    "3. **Prime righe** per vedere la struttura\n",
    "4. **Informazioni sui tipi** di dati\n",
    "5. **Statistiche descrittive** \n",
    "6. **Controllo valori mancanti**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff84003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento del dataset\n",
    "print(\"ğŸ”„ Caricamento del dataset...\")\n",
    "df = pd.read_csv(\"Student_Performance.csv\")\n",
    "\n",
    "# 1. Dimensioni del dataset\n",
    "print(f\"ğŸ“ Dimensioni del dataset: {df.shape[0]} righe Ã— {df.shape[1]} colonne\")\n",
    "print(f\"   â†’ Abbiamo {df.shape[0]} studenti con {df.shape[1]} caratteristiche ciascuno\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“‹ PRIME 5 RIGHE DEL DATASET\")\n",
    "print(\"=\"*60)\n",
    "# 2. Prime righe per vedere la struttura\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"â„¹ï¸  INFORMAZIONI SUL DATASET\")\n",
    "print(\"=\"*60)\n",
    "# 3. Informazioni sui tipi di dati\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š STATISTICHE DESCRITTIVE\")\n",
    "print(\"=\"*60)\n",
    "# 4. Statistiche descrittive delle variabili numeriche\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"â“ CONTROLLO VALORI MANCANTI\")\n",
    "print(\"=\"*60)\n",
    "# 5. Verifica valori mancanti\n",
    "valori_mancanti = df.isnull().sum()\n",
    "print(\"Valori mancanti per colonna:\")\n",
    "for colonna, numero in valori_mancanti.items():\n",
    "    if numero > 0:\n",
    "        print(f\"  âŒ {colonna}: {numero} valori mancanti\")\n",
    "    else:\n",
    "        print(f\"  âœ… {colonna}: nessun valore mancante\")\n",
    "        \n",
    "if valori_mancanti.sum() == 0:\n",
    "    print(\"\\nğŸ‰ Ottimo! Il dataset non ha valori mancanti.\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Attenzione: {valori_mancanti.sum()} valori mancanti totali da gestire.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30cc21",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Sezione 3: Analisi Esplorativa dei Dati (EDA)\n",
    "\n",
    "**PerchÃ© fare l'Analisi Esplorativa?**\n",
    "- ğŸ” **Scoprire pattern** e relazioni nei dati\n",
    "- ğŸ“Š **Visualizzare la distribuzione** delle variabili\n",
    "- ğŸ”— **Identificare correlazioni** tra variabili\n",
    "- ğŸ¯ **Comprendere la variabile target** che vogliamo prevedere\n",
    "- âš ï¸  **Individuare outlier** o anomalie\n",
    "\n",
    "### Grafici che creeremo:\n",
    "1. **Istogramma** della variabile target (Performance Index)\n",
    "2. **Matrice di correlazione** tra tutte le variabili numeriche\n",
    "3. **Boxplot** per confrontare categorie vs performance\n",
    "4. **Scatter plot** per visualizzare relazioni lineari\n",
    "\n",
    "> ğŸ’¡ **Ricorda**: L'EDA Ã¨ fondamentale per capire i dati prima di costruire il modello!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bedaa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo una figura con 6 sottografici per l'analisi esplorativa\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "print(\"ğŸ¨ Creazione visualizzazioni per l'analisi esplorativa...\")\n",
    "\n",
    "# 1. DISTRIBUZIONE DELLA VARIABILE TARGET\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.hist(df['Performance Index'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('ğŸ“Š Distribuzione Performance Index', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Performance Index')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. MATRICE DI CORRELAZIONE\n",
    "plt.subplot(2, 3, 2)\n",
    "# Selezioniamo solo le colonne numeriche per la correlazione\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "# Creiamo la heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={'label': 'Correlazione'})\n",
    "plt.title('ğŸ”— Matrice di Correlazione', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 3. BOXPLOT PER VARIABILI CATEGORICHE\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    plt.subplot(2, 3, 3)\n",
    "    if 'Extracurricular Activities' in df.columns:\n",
    "        sns.boxplot(data=df, x='Extracurricular Activities', y='Performance Index', \n",
    "                   palette='Set2')\n",
    "        plt.title('ğŸƒâ€â™‚ï¸ Performance vs AttivitÃ  Extracurriculari', fontsize=12, fontweight='bold')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. SCATTER PLOT: ORE DI STUDIO vs PERFORMANCE\n",
    "if 'Hours Studied' in df.columns:\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.scatter(df['Hours Studied'], df['Performance Index'], alpha=0.6, color='green')\n",
    "    plt.xlabel('Ore di Studio')\n",
    "    plt.ylabel('Performance Index')\n",
    "    plt.title('â° Ore di Studio vs Performance', fontsize=12, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. SCATTER PLOT: PUNTEGGI PRECEDENTI vs PERFORMANCE\n",
    "if 'Previous Scores' in df.columns:\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.scatter(df['Previous Scores'], df['Performance Index'], alpha=0.6, color='orange')\n",
    "    plt.xlabel('Punteggi Precedenti')\n",
    "    plt.ylabel('Performance Index')\n",
    "    plt.title('ğŸ“š Punteggi Precedenti vs Performance', fontsize=12, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. SCATTER PLOT: ORE DI SONNO vs PERFORMANCE\n",
    "if 'Sleep Hours' in df.columns:\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.scatter(df['Sleep Hours'], df['Performance Index'], alpha=0.6, color='purple')\n",
    "    plt.xlabel('Ore di Sonno')\n",
    "    plt.ylabel('Performance Index')\n",
    "    plt.title('ğŸ˜´ Ore di Sonno vs Performance', fontsize=12, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analizziamo le correlazioni piÃ¹ forti\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ” ANALISI DELLE CORRELAZIONI PIÃ™ FORTI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Troviamo le correlazioni con Performance Index (escludendo l'autocorrelazione)\n",
    "correlazioni_target = correlation_matrix['Performance Index'].drop('Performance Index').sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"Correlazioni con Performance Index (ordinate per forza):\")\n",
    "for variabile, correlazione in correlazioni_target.items():\n",
    "    if abs(correlazione) > 0.3:  # Solo correlazioni significative\n",
    "        emoji = \"ğŸ“ˆ\" if correlazione > 0 else \"ğŸ“‰\"\n",
    "        forza = \"forte\" if abs(correlazione) > 0.7 else \"moderata\" if abs(correlazione) > 0.5 else \"debole\"\n",
    "        print(f\"  {emoji} {variabile}: {correlazione:.3f} (correlazione {forza})\")\n",
    "    \n",
    "print(f\"\\nğŸ’¡ Interpretazione:\")\n",
    "print(f\"   â€¢ Correlazione vicina a +1: relazione positiva forte\")\n",
    "print(f\"   â€¢ Correlazione vicina a -1: relazione negativa forte\") \n",
    "print(f\"   â€¢ Correlazione vicina a 0: nessuna relazione lineare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b06c9",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Sezione 4: Preparazione dei Dati per il Modello\n",
    "\n",
    "**PerchÃ© preparare i dati?**\n",
    "- ğŸ¤– I modelli di **Machine Learning lavorano solo con numeri**\n",
    "- âš–ï¸ Le variabili devono essere sulla **stessa scala**\n",
    "- ğŸ¯ Dobbiamo separare **target** (quello che vogliamo prevedere) da **features** (predittori)\n",
    "\n",
    "### Concetti chiave:\n",
    "\n",
    "**ğŸ¯ Target (y)**: La variabile che vogliamo prevedere (Performance Index)\n",
    "\n",
    "**ğŸ“Š Features (X)**: Le variabili che usiamo per fare la previsione (ore studio, punteggi, ecc.)\n",
    "\n",
    "**ğŸ“ Variabili Categoriche**: Testo (\"Yes\"/\"No\") â†’ vanno trasformate in numeri\n",
    "\n",
    "**ğŸ”¢ Variabili Numeriche**: GiÃ  numeri, ma potrebbero aver bisogno di standardizzazione\n",
    "\n",
    "> ğŸ’¡ **Importante**: Questa separazione Ã¨ fondamentale per qualsiasi progetto di ML!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”§ PREPARAZIONE DEI DATI PER IL MODELLO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. SEPARAZIONE TARGET E FEATURES\n",
    "print(\"1ï¸âƒ£ Separazione target e features...\")\n",
    "\n",
    "# Target: quello che vogliamo prevedere\n",
    "y = df[\"Performance Index\"]\n",
    "print(f\"   ğŸ¯ Target (y): Performance Index\")\n",
    "print(f\"      â†’ Tipo: {y.dtype}\")\n",
    "print(f\"      â†’ Range: {y.min():.1f} - {y.max():.1f}\")\n",
    "\n",
    "# Features: tutte le altre colonne (predittori)\n",
    "X = df.drop(\"Performance Index\", axis=1)\n",
    "print(f\"   ğŸ“Š Features (X): {X.shape[1]} variabili predittive\")\n",
    "print(f\"      â†’ Colonne: {list(X.columns)}\")\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ Identificazione tipi di variabili...\")\n",
    "\n",
    "# 2. IDENTIFICAZIONE VARIABILI CATEGORICHE E NUMERICHE\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numeric_features = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(f\"   ğŸ“ Variabili CATEGORICHE ({len(categorical_features)}):\")\n",
    "for cat in categorical_features:\n",
    "    valori_unici = X[cat].unique()\n",
    "    print(f\"      â€¢ {cat}: {valori_unici} ({len(valori_unici)} categorie)\")\n",
    "\n",
    "print(f\"\\n   ğŸ”¢ Variabili NUMERICHE ({len(numeric_features)}):\")\n",
    "for num in numeric_features:\n",
    "    range_val = f\"{X[num].min():.1f} - {X[num].max():.1f}\"\n",
    "    print(f\"      â€¢ {num}: range {range_val}\")\n",
    "\n",
    "print(\"\\n3ï¸âƒ£ Anteprima della separazione...\")\n",
    "print(\"Target (y) - Prime 5 osservazioni:\")\n",
    "print(y.head())\n",
    "\n",
    "print(\"\\nFeatures (X) - Prime 5 righe:\")\n",
    "display(X.head())\n",
    "\n",
    "print(\"\\nâœ… Dati preparati per il preprocessing!\")\n",
    "print(f\"   â†’ {len(y)} osservazioni\")\n",
    "print(f\"   â†’ {len(categorical_features)} variabili categoriche da codificare\")\n",
    "print(f\"   â†’ {len(numeric_features)} variabili numeriche da standardizzare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc02ee",
   "metadata": {},
   "source": [
    "## âš™ï¸ Sezione 5: Creazione Pipeline di Pre-Processing\n",
    "\n",
    "**Cos'Ã¨ una Pipeline?**\n",
    "- ğŸ”„ Una **sequenza automatica** di trasformazioni sui dati\n",
    "- ğŸ›¡ï¸ **Evita errori** manuali e garantisce consistenza\n",
    "- ğŸš€ **Semplifica** il flusso di lavoro\n",
    "- â™»ï¸ **Riutilizzabile** su nuovi dati\n",
    "\n",
    "### Trasformazioni che applicheremo:\n",
    "\n",
    "**ğŸ“ OneHotEncoder** per variabili categoriche:\n",
    "- Trasforma \"Yes\"/\"No\" in colonne binarie (0/1)\n",
    "- `drop='first'` evita ridondanza (problema multicollinearitÃ )\n",
    "\n",
    "**ğŸ“Š StandardScaler** per variabili numeriche:\n",
    "- Porta tutte le variabili a **media=0** e **deviazione standard=1**\n",
    "- Evita che variabili con scale diverse dominino il modello\n",
    "\n",
    "> ğŸ’¡ **Esempio**: Se ho \"Age\" (0-100) e \"Income\" (0-100000), senza scaling l'Income dominerebbe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12067556",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ—ï¸ CREAZIONE PIPELINE DI PRE-PROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. CREAZIONE DEL PREPROCESSOR\n",
    "print(\"1ï¸âƒ£ Configurazione delle trasformazioni...\")\n",
    "\n",
    "# ColumnTransformer: applica trasformazioni diverse a colonne diverse\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Per variabili categoriche: OneHotEncoder\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\", sparse_output=False), categorical_features),\n",
    "        \n",
    "        # Per variabili numeriche: StandardScaler  \n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "    ],\n",
    "    remainder='drop'  # Ignora colonne non specificate\n",
    ")\n",
    "\n",
    "print(\"   ğŸ“ OneHotEncoder configurato per variabili categoriche:\")\n",
    "print(f\"      â†’ Colonne: {categorical_features}\")\n",
    "print(f\"      â†’ drop='first': evita multicollinearitÃ \")\n",
    "print(f\"      â†’ sparse_output=False: output come array normale\")\n",
    "\n",
    "print(f\"\\n   ğŸ“Š StandardScaler configurato per variabili numeriche:\")\n",
    "print(f\"      â†’ Colonne: {numeric_features}\")\n",
    "print(f\"      â†’ Trasforma a media=0, std=1\")\n",
    "\n",
    "# 2. CREAZIONE DELLA PIPELINE COMPLETA\n",
    "print(\"\\n2ï¸âƒ£ Creazione pipeline completa (preprocessing + modello)...\")\n",
    "\n",
    "# Pipeline: preprocessor + modello di machine learning\n",
    "model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),        # Step 1: Preprocessing\n",
    "    (\"regressor\", LinearRegression())      # Step 2: Modello di regressione\n",
    "])\n",
    "\n",
    "print(\"   ğŸ”„ Pipeline creata con 2 step:\")\n",
    "print(\"      Step 1: Preprocessor (OneHot + Scaling)\")\n",
    "print(\"      Step 2: LinearRegression\")\n",
    "\n",
    "# 3. VISUALIZZAZIONE DELLA PIPELINE\n",
    "print(\"\\n3ï¸âƒ£ Struttura della pipeline:\")\n",
    "print(f\"   Pipeline(steps=[\")\n",
    "print(f\"       ('preprocessor', ColumnTransformer(...)),\")\n",
    "print(f\"       ('regressor', LinearRegression())\")\n",
    "print(f\"   ])\")\n",
    "\n",
    "print(\"\\nâœ… Pipeline di preprocessing creata con successo!\")\n",
    "print(\"\\nğŸ§  Cosa succede quando usiamo la pipeline:\")\n",
    "print(\"   1. I dati passano prima al preprocessor\")\n",
    "print(\"   2. Variabili categoriche â†’ OneHot encoding\")\n",
    "print(\"   3. Variabili numeriche â†’ Standardizzazione\")\n",
    "print(\"   4. Dati trasformati â†’ Modello di regressione\")\n",
    "print(\"   5. Output â†’ Previsioni finali\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3417271",
   "metadata": {},
   "source": [
    "## ğŸš€ Sezione 6: Addestramento e Valutazione del Modello\n",
    "\n",
    "**PerchÃ© dividere Train/Test?**\n",
    "- ğŸ§  **Training Set**: Il modello \"impara\" da questi dati\n",
    "- ğŸ§ª **Test Set**: Valutiamo quanto bene il modello generalizza su dati mai visti\n",
    "- ğŸš« **NO DATA LEAKAGE**: Il test set deve essere completamente ignoto durante l'addestramento\n",
    "\n",
    "### Metriche di Valutazione per la Regressione:\n",
    "\n",
    "**ğŸ“Š RÂ² (R-quadrato)**:\n",
    "- Range: 0-1 (piÃ¹ alto = migliore)\n",
    "- Indica **quanto % della varianza** Ã¨ spiegata dal modello\n",
    "- RÂ² = 0.8 â†’ Il modello spiega l'80% della variabilitÃ \n",
    "\n",
    "**ğŸ“ MAE (Mean Absolute Error)**:\n",
    "- Errore medio in **valore assoluto**\n",
    "- PiÃ¹ basso = migliore\n",
    "- Stessa unitÃ  della variabile target\n",
    "\n",
    "**ğŸ¯ RMSE (Root Mean Squared Error)**:\n",
    "- Penalizza di piÃ¹ gli **errori grandi**\n",
    "- PiÃ¹ basso = migliore\n",
    "- PiÃ¹ sensibile agli outlier rispetto al MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f43f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ ADDESTRAMENTO E VALUTAZIONE DEL MODELLO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. DIVISIONE TRAIN/TEST\n",
    "print(\"1ï¸âƒ£ Divisione del dataset in Training e Test...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,        # 20% per il test, 80% per il training\n",
    "    random_state=42,      # Per risultati riproducibili\n",
    "    stratify=None         # Non necessaria per la regressione\n",
    ")\n",
    "\n",
    "print(f\"   ğŸ“š Training Set: {X_train.shape[0]} campioni ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   ğŸ§ª Test Set: {X_test.shape[0]} campioni ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   âœ… Divisione completata!\")\n",
    "\n",
    "# 2. ADDESTRAMENTO DEL MODELLO\n",
    "print(\"\\n2ï¸âƒ£ Addestramento del modello...\")\n",
    "\n",
    "# Addestriamo la pipeline completa sui dati di training\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"   ğŸ§  Modello addestrato con successo!\")\n",
    "print(\"   ğŸ“Š Il modello ha imparato le relazioni tra features e target\")\n",
    "\n",
    "# 3. PREVISIONI\n",
    "print(\"\\n3ï¸âƒ£ Generazione delle previsioni...\")\n",
    "\n",
    "# Previsioni sui dati di training\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(f\"   ğŸ“ˆ Previsioni su Training Set: {len(y_train_pred)} valori\")\n",
    "\n",
    "# Previsioni sui dati di test\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(f\"   ğŸ” Previsioni su Test Set: {len(y_test_pred)} valori\")\n",
    "\n",
    "# 4. CALCOLO DELLE METRICHE\n",
    "print(\"\\n4ï¸âƒ£ Calcolo metriche di performance...\")\n",
    "\n",
    "# Metriche sul Training Set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "rmse_train = mean_squared_error(y_train, y_train_pred)**0.5\n",
    "\n",
    "# Metriche sul Test Set  \n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse_test = mean_squared_error(y_test, y_test_pred)**0.5\n",
    "\n",
    "# 5. PRESENTAZIONE DEI RISULTATI\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“Š RISULTATI DEL MODELLO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"ğŸ‹ï¸â€â™‚ï¸ TRAINING SET:\")\n",
    "print(f\"   RÂ²   : {r2_train:.4f} ({r2_train*100:.1f}% della varianza spiegata)\")\n",
    "print(f\"   MAE  : {mae_train:.3f} punti di errore medio\")\n",
    "print(f\"   RMSE : {rmse_train:.3f} punti (penalizza errori grandi)\")\n",
    "\n",
    "print(f\"\\nğŸ§ª TEST SET (performance su dati mai visti):\")\n",
    "print(f\"   RÂ²   : {r2_test:.4f} ({r2_test*100:.1f}% della varianza spiegata)\")\n",
    "print(f\"   MAE  : {mae_test:.3f} punti di errore medio\")\n",
    "print(f\"   RMSE : {rmse_test:.3f} punti (penalizza errori grandi)\")\n",
    "\n",
    "# 6. INTERPRETAZIONE AUTOMATICA\n",
    "print(f\"\\nğŸ¯ INTERPRETAZIONE:\")\n",
    "if abs(r2_train - r2_test) < 0.05:\n",
    "    print(f\"   âœ… Buona generalizzazione (differenza RÂ² train-test: {abs(r2_train-r2_test):.3f})\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Possibile overfitting (differenza RÂ² train-test: {abs(r2_train-r2_test):.3f})\")\n",
    "\n",
    "if r2_test > 0.8:\n",
    "    print(f\"   ğŸŒŸ Ottima capacitÃ  predittiva!\")\n",
    "elif r2_test > 0.6:\n",
    "    print(f\"   ğŸ‘ Buona capacitÃ  predittiva\")\n",
    "elif r2_test > 0.4:\n",
    "    print(f\"   ğŸ¤” CapacitÃ  predittiva moderata\")\n",
    "else:\n",
    "    print(f\"   âŒ CapacitÃ  predittiva limitata\")\n",
    "\n",
    "print(f\"   ğŸ’¡ In media sbagliamo di {mae_test:.1f} punti nelle previsioni\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535ce449",
   "metadata": {},
   "source": [
    "## ğŸ” Sezione 7: Analisi dell'Importanza delle Variabili\n",
    "\n",
    "**Cos'Ã¨ un Coefficiente nella Regressione Lineare?**\n",
    "\n",
    "La regressione lineare multipla crea un'equazione del tipo:\n",
    "```\n",
    "Performance = Î²â‚€ + Î²â‚Ã—Hours_Studied + Î²â‚‚Ã—Previous_Scores + Î²â‚ƒÃ—Sleep_Hours + ...\n",
    "```\n",
    "\n",
    "### Interpretazione dei Coefficienti:\n",
    "\n",
    "**ğŸ”¢ Valore del Coefficiente**:\n",
    "- **Positivo** (+): â†—ï¸ Se la variabile aumenta, il target aumenta\n",
    "- **Negativo** (-): â†˜ï¸ Se la variabile aumenta, il target diminuisce\n",
    "- **Vicino a 0**: ğŸ¤·â€â™‚ï¸ La variabile ha poco impatto\n",
    "\n",
    "**ğŸ“ Magnitudine (valore assoluto)**:\n",
    "- **Grande**: ğŸ’ª Variabile molto influente\n",
    "- **Piccola**: ğŸ¤ Variabile poco influente\n",
    "\n",
    "**ğŸ  Intercetta (Î²â‚€)**:\n",
    "- Valore del target quando **tutte le features = 0**\n",
    "\n",
    "> âš ï¸ **Attenzione**: I coefficienti sono interpretabili solo se le variabili sono standardizzate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04731dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”¬ ANALISI DELL'IMPORTANZA DELLE VARIABILI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. ESTRAZIONE DEI COEFFICIENTI\n",
    "print(\"1ï¸âƒ£ Estrazione coefficienti dal modello addestrato...\")\n",
    "\n",
    "# Otteniamo i nomi delle features dopo il preprocessing\n",
    "feature_names = model.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "print(f\"   ğŸ“‹ Numero totale di features dopo preprocessing: {len(feature_names)}\")\n",
    "\n",
    "# Coefficienti del modello di regressione lineare\n",
    "coefficients = model.named_steps[\"regressor\"].coef_\n",
    "print(f\"   ğŸ”¢ Numero di coefficienti estratti: {len(coefficients)}\")\n",
    "\n",
    "# Intercetta del modello\n",
    "intercept = model.named_steps[\"regressor\"].intercept_\n",
    "print(f\"   ğŸ  Intercetta del modello: {intercept:.4f}\")\n",
    "\n",
    "# 2. CREAZIONE DATAFRAME PER ANALISI\n",
    "print(\"\\n2ï¸âƒ£ Organizzazione dei coefficienti...\")\n",
    "\n",
    "# Creiamo un DataFrame per analizzare meglio i coefficienti\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficiente': coefficients,\n",
    "    'Importanza_Assoluta': np.abs(coefficients)  # Valore assoluto per ranking\n",
    "}).sort_values('Importanza_Assoluta', ascending=False)\n",
    "\n",
    "# Puliamo i nomi delle features per renderli piÃ¹ leggibili\n",
    "coef_df['Feature_Pulita'] = coef_df['Feature'].str.replace('cat__', '').str.replace('num__', '')\n",
    "\n",
    "print(f\"   âœ… DataFrame creato e ordinato per importanza\")\n",
    "\n",
    "# 3. TOP VARIABILI PIÃ™ INFLUENTI\n",
    "print(\"\\n3ï¸âƒ£ Identificazione delle variabili piÃ¹ influenti...\")\n",
    "\n",
    "print(f\"\\nğŸ† TOP 10 VARIABILI PIÃ™ INFLUENTI:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Rank':<4} {'Variabile':<25} {'Coefficiente':<12} {'Impatto':<15}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for i, (_, row) in enumerate(coef_df.head(10).iterrows(), 1):\n",
    "    # Determiniamo il tipo di impatto\n",
    "    if row['Coefficiente'] > 0:\n",
    "        impatto = \"â†—ï¸ Aumenta\"\n",
    "    else:\n",
    "        impatto = \"â†˜ï¸ Diminuisce\"\n",
    "    \n",
    "    print(f\"{i:<4} {row['Feature_Pulita']:<25} {row['Coefficiente']:<12.4f} {impatto}\")\n",
    "\n",
    "# 4. STATISTICHE SUI COEFFICIENTI\n",
    "print(f\"\\nğŸ“Š STATISTICHE SUI COEFFICIENTI:\")\n",
    "print(f\"   â€¢ Coefficiente piÃ¹ alto: {coef_df['Coefficiente'].max():.4f}\")\n",
    "print(f\"   â€¢ Coefficiente piÃ¹ basso: {coef_df['Coefficiente'].min():.4f}\")\n",
    "print(f\"   â€¢ Media coefficienti: {coef_df['Coefficiente'].mean():.4f}\")\n",
    "print(f\"   â€¢ Intercetta: {intercept:.4f}\")\n",
    "\n",
    "# 5. INTERPRETAZIONE BUSINESS\n",
    "print(f\"\\nğŸ’¼ INTERPRETAZIONE BUSINESS (Top 3 variabili):\")\n",
    "for i, (_, row) in enumerate(coef_df.head(3).iterrows(), 1):\n",
    "    if row['Coefficiente'] > 0:\n",
    "        effect = \"aumenta\"\n",
    "        emoji = \"ğŸ“ˆ\"\n",
    "    else:\n",
    "        effect = \"diminuisce\"  \n",
    "        emoji = \"ğŸ“‰\"\n",
    "    \n",
    "    print(f\"   {emoji} {row['Feature_Pulita']}: {effect} la performance di {abs(row['Coefficiente']):.3f} punti\")\n",
    "\n",
    "print(f\"\\nğŸ§® EQUAZIONE DEL MODELLO (semplificata):\")\n",
    "print(f\"Performance = {intercept:.3f}\", end=\"\")\n",
    "for _, row in coef_df.head(3).iterrows():\n",
    "    sign = \"+\" if row['Coefficiente'] >= 0 else \"\"\n",
    "    print(f\" {sign}{row['Coefficiente']:.3f}Ã—{row['Feature_Pulita']}\", end=\"\")\n",
    "print(\" + ...\")\n",
    "\n",
    "print(f\"\\nâœ… Analisi dei coefficienti completata!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bef755",
   "metadata": {},
   "source": [
    "## ğŸ“Š Sezione 8: Visualizzazioni e Diagnosi del Modello\n",
    "\n",
    "**PerchÃ© Visualizzare i Risultati?**\n",
    "- ğŸ‘€ **Vedere Ã¨ credere**: I grafici rivelano pattern che i numeri nascondono\n",
    "- ğŸ” **Diagnosticare problemi**: Individuare overfitting, outlier, violazioni assunzioni\n",
    "- ğŸ“ˆ **Comunicare risultati**: Presentare in modo comprensibile ai stakeholder\n",
    "\n",
    "### Grafici di Diagnosi che Creeremo:\n",
    "\n",
    "**1. ğŸ¯ Scatter Plot: Valori Reali vs Predetti**\n",
    "- Punti vicini alla linea diagonale = buone previsioni\n",
    "- Punti sparsi = previsioni imprecise\n",
    "\n",
    "**2. ğŸ“‰ Grafico dei Residui**\n",
    "- Residui = Differenza tra valori reali e predetti\n",
    "- Pattern casuali = modello buono\n",
    "- Pattern sistematici = problemi nel modello\n",
    "\n",
    "**3. ğŸ“Š Importanza delle Variabili**\n",
    "- Bar chart dei coefficienti piÃ¹ importanti\n",
    "- Visualizza quale variabile ha piÃ¹ peso\n",
    "\n",
    "**4. ğŸ“‹ Distribuzione degli Errori**\n",
    "- Istogramma dei residui\n",
    "- Dovrebbe assomigliare a una distribuzione normale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“Š VISUALIZZAZIONI E DIAGNOSI DEL MODELLO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Creiamo una figura con 4 sottografici per la diagnosi del modello\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('ğŸ” Diagnosi del Modello di Regressione Lineare Multipla', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Calcoliamo i residui per l'analisi\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# 1. GRAFICO: VALORI REALI vs PREDETTI\n",
    "axes[0,0].scatter(y_test, y_test_pred, alpha=0.6, color='blue', s=50)\n",
    "# Linea perfetta (previsioni = valori reali)\n",
    "min_val, max_val = y.min(), y.max()\n",
    "axes[0,0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=3, label='Previsione Perfetta')\n",
    "axes[0,0].set_xlabel('Valori Reali (Performance Index)', fontsize=12)\n",
    "axes[0,0].set_ylabel('Valori Predetti', fontsize=12)\n",
    "axes[0,0].set_title('ğŸ¯ Valori Reali vs Predetti', fontsize=14, fontweight='bold')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Aggiungiamo l'RÂ² nel grafico\n",
    "axes[0,0].text(0.05, 0.95, f'RÂ² = {r2_test:.3f}', transform=axes[0,0].transAxes, \n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
    "               fontsize=12, fontweight='bold')\n",
    "\n",
    "# 2. GRAFICO: RESIDUI vs VALORI PREDETTI\n",
    "axes[0,1].scatter(y_test_pred, residuals, alpha=0.6, color='green', s=50)\n",
    "axes[0,1].axhline(y=0, color='red', linestyle='--', linewidth=2, label='Residui = 0')\n",
    "axes[0,1].set_xlabel('Valori Predetti', fontsize=12)\n",
    "axes[0,1].set_ylabel('Residui (Reale - Predetto)', fontsize=12)\n",
    "axes[0,1].set_title('ğŸ“‰ Grafico dei Residui', fontsize=14, fontweight='bold')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,1].legend()\n",
    "\n",
    "# 3. GRAFICO: IMPORTANZA DELLE VARIABILI (TOP 8)\n",
    "top_features = coef_df.head(8)\n",
    "colors = ['red' if coef < 0 else 'blue' for coef in top_features['Coefficiente']]\n",
    "bars = axes[1,0].barh(range(len(top_features)), top_features['Coefficiente'], color=colors, alpha=0.7)\n",
    "axes[1,0].set_yticks(range(len(top_features)))\n",
    "axes[1,0].set_yticklabels(top_features['Feature_Pulita'], fontsize=10)\n",
    "axes[1,0].set_xlabel('Coefficiente', fontsize=12)\n",
    "axes[1,0].set_title('ğŸ“Š Top 8 Coefficienti del Modello', fontsize=14, fontweight='bold')\n",
    "axes[1,0].grid(True, alpha=0.3, axis='x')\n",
    "axes[1,0].axvline(x=0, color='black', linewidth=1)\n",
    "\n",
    "# Aggiungiamo i valori sulle barre\n",
    "for i, (bar, coef) in enumerate(zip(bars, top_features['Coefficiente'])):\n",
    "    width = bar.get_width()\n",
    "    label_x = width + 0.01 if width >= 0 else width - 0.01\n",
    "    ha = 'left' if width >= 0 else 'right'\n",
    "    axes[1,0].text(label_x, bar.get_y() + bar.get_height()/2, f'{coef:.3f}', \n",
    "                   ha=ha, va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# 4. GRAFICO: DISTRIBUZIONE DEI RESIDUI\n",
    "axes[1,1].hist(residuals, bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
    "axes[1,1].set_xlabel('Residui', fontsize=12)\n",
    "axes[1,1].set_ylabel('Frequenza', fontsize=12)\n",
    "axes[1,1].set_title('ğŸ“‹ Distribuzione dei Residui', fontsize=14, fontweight='bold')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Aggiungiamo statistiche sui residui\n",
    "mean_residuals = np.mean(residuals)\n",
    "std_residuals = np.std(residuals)\n",
    "axes[1,1].axvline(mean_residuals, color='red', linestyle='--', linewidth=2, \n",
    "                  label=f'Media: {mean_residuals:.3f}')\n",
    "axes[1,1].text(0.05, 0.95, f'Std: {std_residuals:.3f}', transform=axes[1,1].transAxes,\n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7),\n",
    "               fontsize=10)\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# INTERPRETAZIONE DEI GRAFICI\n",
    "print(\"\\nğŸ” INTERPRETAZIONE DEI GRAFICI:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"ğŸ“Š GRAFICO 1 - Valori Reali vs Predetti:\")\n",
    "if r2_test > 0.8:\n",
    "    print(f\"   âœ… Punti molto vicini alla linea rossa = ottime previsioni\")\n",
    "elif r2_test > 0.6:\n",
    "    print(f\"   ğŸ‘ Buona distribuzione attorno alla linea rossa\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Punti sparsi = previsioni poco accurate\")\n",
    "\n",
    "print(f\"\\nğŸ“‰ GRAFICO 2 - Residui:\")\n",
    "if abs(np.mean(residuals)) < 0.5:\n",
    "    print(f\"   âœ… Residui centrati sullo zero = nessun bias sistematico\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Residui non centrati = possibile bias nel modello\")\n",
    "\n",
    "print(f\"\\nğŸ“Š GRAFICO 3 - Importanza Variabili:\")\n",
    "top_var = coef_df.iloc[0]['Feature_Pulita']\n",
    "print(f\"   ğŸ† Variabile piÃ¹ importante: {top_var}\")\n",
    "print(f\"   ğŸ“ˆ Coefficienti positivi (blu) aumentano la performance\")\n",
    "print(f\"   ğŸ“‰ Coefficienti negativi (rossi) diminuiscono la performance\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ GRAFICO 4 - Distribuzione Residui:\")\n",
    "if abs(mean_residuals) < std_residuals/3:\n",
    "    print(f\"   âœ… Distribuzione simmetrica = assunzioni del modello rispettate\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Distribuzione asimmetrica = possibili violazioni assunzioni\")\n",
    "\n",
    "print(f\"\\nğŸ“ RIASSUNTO DIAGNOSTICO:\")\n",
    "print(f\"   â€¢ Media residui: {mean_residuals:.3f} (dovrebbe essere ~0)\")\n",
    "print(f\"   â€¢ Std residui: {std_residuals:.3f}\")\n",
    "print(f\"   â€¢ RÂ² test: {r2_test:.3f}\")\n",
    "print(f\"   â€¢ Modello {'adeguato' if r2_test > 0.6 else 'da migliorare'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffca551",
   "metadata": {},
   "source": [
    "## ğŸ“ Conclusioni e Riassunto della Lezione\n",
    "\n",
    "### ğŸ“‹ Cosa Abbiamo Imparato:\n",
    "\n",
    "**1. ğŸ” Analisi Esplorativa dei Dati**\n",
    "- Come esplorare e comprendere un dataset\n",
    "- Identificare correlazioni tra variabili\n",
    "- Visualizzare distribuzioni e relazioni\n",
    "\n",
    "**2. ğŸ› ï¸ Preprocessing dei Dati**\n",
    "- Separare target e features\n",
    "- Gestire variabili categoriche (OneHot Encoding)\n",
    "- Standardizzare variabili numeriche (StandardScaler)\n",
    "\n",
    "**3. ğŸš€ Machine Learning Pipeline**\n",
    "- Costruire una pipeline automatica\n",
    "- Dividere dati in train/test\n",
    "- Addestrare un modello di regressione lineare multipla\n",
    "\n",
    "**4. ğŸ“Š Valutazione del Modello**\n",
    "- Metriche: RÂ², MAE, RMSE\n",
    "- Interpretare la bontÃ  delle previsioni\n",
    "- Riconoscere overfitting\n",
    "\n",
    "**5. ğŸ”¬ Interpretazione dei Risultati**\n",
    "- Analizzare coefficienti e loro significato\n",
    "- Identificare variabili piÃ¹ importanti\n",
    "- Diagnosticare il modello con visualizzazioni\n",
    "\n",
    "### ğŸ§  Concetti Chiave da Ricordare:\n",
    "\n",
    "> **Regressione Lineare Multipla**: Prevede valori continui usando piÃ¹ variabili predittive\n",
    "\n",
    "> **Pipeline**: Automatizza preprocessing e modelling per evitare errori\n",
    "\n",
    "> **Train/Test Split**: Essenziale per valutare la capacitÃ  di generalizzazione\n",
    "\n",
    "> **Coefficienti**: Indicano l'impatto di ogni variabile sulla previsione\n",
    "\n",
    "### ğŸš€ Prossimi Passi:\n",
    "\n",
    "- **Migliorare il modello**: Feature engineering, polinomiali, regolarizzazione\n",
    "- **Altri algoritmi**: Random Forest, SVM, Neural Networks\n",
    "- **Validazione robusta**: Cross-validation, metriche multiple\n",
    "- **Deploy**: Portare il modello in produzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ ESEMPIO PRATICO: Previsione per un Nuovo Studente\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ¯ ESEMPIO PRATICO: PREVISIONE PER UN NUOVO STUDENTE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Creiamo un esempio di nuovo studente\n",
    "nuovo_studente = pd.DataFrame({\n",
    "    'Hours Studied': [7],                        # 7 ore di studio al giorno\n",
    "    'Previous Scores': [85],                     # Punteggio precedente 85/100\n",
    "    'Extracurricular Activities': ['Yes'],       # Partecipa ad attivitÃ  extra\n",
    "    'Sleep Hours': [8],                          # 8 ore di sonno\n",
    "    'Sample Question Papers Practiced': [5]      # Ha fatto 5 test di pratica\n",
    "})\n",
    "\n",
    "print(\"ğŸ“ Caratteristiche del nuovo studente:\")\n",
    "display(nuovo_studente)\n",
    "\n",
    "# Facciamo la previsione\n",
    "previsione = model.predict(nuovo_studente)\n",
    "\n",
    "print(f\"\\nğŸ”® PREVISIONE DEL MODELLO:\")\n",
    "print(f\"   Performance Index prevista: {previsione[0]:.2f}/100\")\n",
    "\n",
    "# Calcoliamo un intervallo di confidenza approssimativo\n",
    "intervallo = rmse_test * 1.96  # ~95% di confidenza\n",
    "print(f\"   Intervallo di confidenza (~95%): {previsione[0]-intervallo:.1f} - {previsione[0]+intervallo:.1f}\")\n",
    "\n",
    "# Interpretazione\n",
    "if previsione[0] >= 90:\n",
    "    performance_level = \"ğŸŒŸ Eccellente\"\n",
    "elif previsione[0] >= 80:\n",
    "    performance_level = \"ğŸ‘ Molto Buona\"\n",
    "elif previsione[0] >= 70:\n",
    "    performance_level = \"âœ… Buona\"\n",
    "elif previsione[0] >= 60:\n",
    "    performance_level = \"ğŸ¤” Sufficiente\"\n",
    "else:\n",
    "    performance_level = \"âŒ Da Migliorare\"\n",
    "\n",
    "print(f\"   Livello di performance: {performance_level}\")\n",
    "\n",
    "print(f\"\\nâœ… ESERCIZIO COMPLETATO CON SUCCESSO!\")\n",
    "print(f\"Hai imparato a costruire e utilizzare un modello di regressione lineare multipla!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
