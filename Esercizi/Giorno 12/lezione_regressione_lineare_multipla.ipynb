{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e513a006",
   "metadata": {},
   "source": [
    "# üìä Lezione: Regressione Lineare Multipla per la Previsione delle Performance Studenti\n",
    "\n",
    "## üéØ Obiettivi della Lezione\n",
    "\n",
    "In questa lezione imparerete:\n",
    "- **Cos'√® la Regressione Lineare Multipla** e quando utilizzarla\n",
    "- Come **esplorare e preparare i dati** per il machine learning\n",
    "- Come **costruire e valutare** un modello predittivo\n",
    "- Come **interpretare i risultati** e l'importanza delle variabili\n",
    "- Le **migliori pratiche** per progetti di Data Science\n",
    "\n",
    "## üìã Caso di Studio\n",
    "\n",
    "**Problema**: Prevedere l'indice di performance degli studenti (Performance Index) basandosi su:\n",
    "- ‚è∞ Ore di studio\n",
    "- üìö Punteggi precedenti  \n",
    "- üèÉ‚Äç‚ôÇÔ∏è Attivit√† extracurriculari\n",
    "- üò¥ Ore di sonno\n",
    "- üìù Numero di test di pratica\n",
    "\n",
    "**Tipo di Problema**: Regressione (previsione di valori continui)\n",
    "**Algoritmo**: Regressione Lineare Multipla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d2667e",
   "metadata": {},
   "source": [
    "## üìö Sezione 1: Importazione delle Librerie\n",
    "\n",
    "Prima di iniziare qualsiasi progetto di Data Science, dobbiamo importare le librerie necessarie. Ogni libreria ha un ruolo specifico:\n",
    "\n",
    "- **pandas**: Manipolazione e analisi dei dati (DataFrame, lettura CSV, ecc.)\n",
    "- **numpy**: Calcoli numerici e operazioni su array\n",
    "- **matplotlib**: Creazione di grafici e visualizzazioni\n",
    "- **seaborn**: Visualizzazioni statistiche avanzate e pi√π eleganti\n",
    "- **sklearn**: Machine Learning (modelli, preprocessing, metriche, ecc.)\n",
    "\n",
    "> üí° **Tip**: √à una buona pratica importare tutte le librerie all'inizio del progetto per avere una visione chiara delle dipendenze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ee3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerie per manipolazione dati\n",
    "import pandas as pd           # Analisi e manipolazione dati strutturati\n",
    "import numpy as np           # Calcoli numerici e operazioni matematiche\n",
    "\n",
    "# Librerie per visualizzazione\n",
    "import matplotlib.pyplot as plt  # Creazione di grafici base\n",
    "import seaborn as sns           # Visualizzazioni statistiche avanzate\n",
    "\n",
    "# Librerie per Machine Learning\n",
    "from sklearn.model_selection import train_test_split  # Divisione dataset train/test\n",
    "from sklearn.compose import ColumnTransformer         # Preprocessing colonne diverse\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler  # Encoding e scaling\n",
    "from sklearn.pipeline import Pipeline                 # Creazione pipeline ML\n",
    "from sklearn.linear_model import LinearRegression     # Modello di regressione lineare\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error  # Metriche\n",
    "\n",
    "# Configurazione per grafici pi√π belli\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Tutte le librerie importate con successo!\")\n",
    "print(\"Ora siamo pronti per iniziare l'analisi dei dati.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e55b67",
   "metadata": {},
   "source": [
    "## üîç Sezione 2: Caricamento e Esplorazione Iniziale dei Dati\n",
    "\n",
    "**Perch√© √® importante l'esplorazione iniziale?**\n",
    "- üìä Comprendere la **struttura** e **dimensioni** del dataset\n",
    "- üîç Identificare **valori mancanti** o **anomalie**\n",
    "- üìà Avere una **prima impressione** sui dati\n",
    "- üßê Verificare che il dataset sia **corretto** e **completo**\n",
    "\n",
    "### Step dell'esplorazione:\n",
    "1. **Caricamento** del dataset\n",
    "2. **Dimensioni** del dataset (righe √ó colonne)\n",
    "3. **Prime righe** per vedere la struttura\n",
    "4. **Informazioni sui tipi** di dati\n",
    "5. **Statistiche descrittive** \n",
    "6. **Controllo valori mancanti**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff84003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento del dataset\n",
    "print(\"üîÑ Caricamento del dataset...\")\n",
    "df = pd.read_csv(\"Student_Performance.csv\")\n",
    "\n",
    "# 1. Dimensioni del dataset\n",
    "print(f\"üìè Dimensioni del dataset: {df.shape[0]} righe √ó {df.shape[1]} colonne\")\n",
    "print(f\"   ‚Üí Abbiamo {df.shape[0]} studenti con {df.shape[1]} caratteristiche ciascuno\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã PRIME 5 RIGHE DEL DATASET\")\n",
    "print(\"=\"*60)\n",
    "# 2. Prime righe per vedere la struttura\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚ÑπÔ∏è  INFORMAZIONI SUL DATASET\")\n",
    "print(\"=\"*60)\n",
    "# 3. Informazioni sui tipi di dati\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä STATISTICHE DESCRITTIVE\")\n",
    "print(\"=\"*60)\n",
    "# 4. Statistiche descrittive delle variabili numeriche\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚ùì CONTROLLO VALORI MANCANTI\")\n",
    "print(\"=\"*60)\n",
    "# 5. Verifica valori mancanti\n",
    "valori_mancanti = df.isnull().sum()\n",
    "print(\"Valori mancanti per colonna:\")\n",
    "for colonna, numero in valori_mancanti.items():\n",
    "    if numero > 0:\n",
    "        print(f\"  ‚ùå {colonna}: {numero} valori mancanti\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ {colonna}: nessun valore mancante\")\n",
    "        \n",
    "if valori_mancanti.sum() == 0:\n",
    "    print(\"\\nüéâ Ottimo! Il dataset non ha valori mancanti.\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Attenzione: {valori_mancanti.sum()} valori mancanti totali da gestire.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30cc21",
   "metadata": {},
   "source": [
    "## üìà Sezione 3: Analisi Esplorativa dei Dati (EDA)\n",
    "\n",
    "**Perch√© fare l'Analisi Esplorativa?**\n",
    "- üîç **Scoprire pattern** e relazioni nei dati\n",
    "- üìä **Visualizzare la distribuzione** delle variabili\n",
    "- üîó **Identificare correlazioni** tra variabili\n",
    "- üéØ **Comprendere la variabile target** che vogliamo prevedere\n",
    "- ‚ö†Ô∏è  **Individuare outlier** o anomalie\n",
    "\n",
    "### Grafici che creeremo:\n",
    "1. **Istogramma** della variabile target (Performance Index)\n",
    "2. **Matrice di correlazione** tra tutte le variabili numeriche\n",
    "3. **Boxplot** per confrontare categorie vs performance\n",
    "4. **Scatter plot** per visualizzare relazioni lineari\n",
    "\n",
    "> üí° **Ricorda**: L'EDA √® fondamentale per capire i dati prima di costruire il modello!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bedaa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo una figura con 6 sottografici per l'analisi esplorativa\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "print(\"üé® Creazione visualizzazioni per l'analisi esplorativa...\")\n",
    "\n",
    "# 1. DISTRIBUZIONE DELLA VARIABILE TARGET\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.hist(df['Performance Index'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('üìä Distribuzione Performance Index', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Performance Index')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. MATRICE DI CORRELAZIONE\n",
    "plt.subplot(2, 3, 2)\n",
    "# Selezioniamo solo le colonne numeriche per la correlazione\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "# Creiamo la heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={'label': 'Correlazione'})\n",
    "plt.title('üîó Matrice di Correlazione', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 3. BOXPLOT PER VARIABILI CATEGORICHE\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    plt.subplot(2, 3, 3)\n",
    "    if 'Extracurricular Activities' in df.columns:\n",
    "        sns.boxplot(data=df, x='Extracurricular Activities', y='Performance Index', \n",
    "                   palette='Set2')\n",
    "        plt.title('üèÉ‚Äç‚ôÇÔ∏è Performance vs Attivit√† Extracurriculari', fontsize=12, fontweight='bold')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. SCATTER PLOT: ORE DI STUDIO vs PERFORMANCE\n",
    "if 'Hours Studied' in df.columns:\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.scatter(df['Hours Studied'], df['Performance Index'], alpha=0.6, color='green')\n",
    "    plt.xlabel('Ore di Studio')\n",
    "    plt.ylabel('Performance Index')\n",
    "    plt.title('‚è∞ Ore di Studio vs Performance', fontsize=12, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. SCATTER PLOT: PUNTEGGI PRECEDENTI vs PERFORMANCE\n",
    "if 'Previous Scores' in df.columns:\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.scatter(df['Previous Scores'], df['Performance Index'], alpha=0.6, color='orange')\n",
    "    plt.xlabel('Punteggi Precedenti')\n",
    "    plt.ylabel('Performance Index')\n",
    "    plt.title('üìö Punteggi Precedenti vs Performance', fontsize=12, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. SCATTER PLOT: ORE DI SONNO vs PERFORMANCE\n",
    "if 'Sleep Hours' in df.columns:\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.scatter(df['Sleep Hours'], df['Performance Index'], alpha=0.6, color='purple')\n",
    "    plt.xlabel('Ore di Sonno')\n",
    "    plt.ylabel('Performance Index')\n",
    "    plt.title('üò¥ Ore di Sonno vs Performance', fontsize=12, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analizziamo le correlazioni pi√π forti\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç ANALISI DELLE CORRELAZIONI PI√ô FORTI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Troviamo le correlazioni con Performance Index (escludendo l'autocorrelazione)\n",
    "correlazioni_target = correlation_matrix['Performance Index'].drop('Performance Index').sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"Correlazioni con Performance Index (ordinate per forza):\")\n",
    "for variabile, correlazione in correlazioni_target.items():\n",
    "    if abs(correlazione) > 0.3:  # Solo correlazioni significative\n",
    "        emoji = \"üìà\" if correlazione > 0 else \"üìâ\"\n",
    "        forza = \"forte\" if abs(correlazione) > 0.7 else \"moderata\" if abs(correlazione) > 0.5 else \"debole\"\n",
    "        print(f\"  {emoji} {variabile}: {correlazione:.3f} (correlazione {forza})\")\n",
    "    \n",
    "print(f\"\\nüí° Interpretazione:\")\n",
    "print(f\"   ‚Ä¢ Correlazione vicina a +1: relazione positiva forte\")\n",
    "print(f\"   ‚Ä¢ Correlazione vicina a -1: relazione negativa forte\") \n",
    "print(f\"   ‚Ä¢ Correlazione vicina a 0: nessuna relazione lineare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b06c9",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Sezione 4: Preparazione dei Dati per il Modello\n",
    "\n",
    "**Perch√© preparare i dati?**\n",
    "- ü§ñ I modelli di **Machine Learning lavorano solo con numeri**\n",
    "- ‚öñÔ∏è Le variabili devono essere sulla **stessa scala**\n",
    "- üéØ Dobbiamo separare **target** (quello che vogliamo prevedere) da **features** (predittori)\n",
    "\n",
    "### Concetti chiave:\n",
    "\n",
    "**üéØ Target (y)**: La variabile che vogliamo prevedere (Performance Index)\n",
    "\n",
    "**üìä Features (X)**: Le variabili che usiamo per fare la previsione (ore studio, punteggi, ecc.)\n",
    "\n",
    "**üìù Variabili Categoriche**: Testo (\"Yes\"/\"No\") ‚Üí vanno trasformate in numeri\n",
    "\n",
    "**üî¢ Variabili Numeriche**: Gi√† numeri, ma potrebbero aver bisogno di standardizzazione\n",
    "\n",
    "> üí° **Importante**: Questa separazione √® fondamentale per qualsiasi progetto di ML!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß PREPARAZIONE DEI DATI PER IL MODELLO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. SEPARAZIONE TARGET E FEATURES\n",
    "print(\"1Ô∏è‚É£ Separazione target e features...\")\n",
    "\n",
    "# Target: quello che vogliamo prevedere\n",
    "y = df[\"Performance Index\"]\n",
    "print(f\"   üéØ Target (y): Performance Index\")\n",
    "print(f\"      ‚Üí Tipo: {y.dtype}\")\n",
    "print(f\"      ‚Üí Range: {y.min():.1f} - {y.max():.1f}\")\n",
    "\n",
    "# Features: tutte le altre colonne (predittori)\n",
    "X = df.drop(\"Performance Index\", axis=1)\n",
    "print(f\"   üìä Features (X): {X.shape[1]} variabili predittive\")\n",
    "print(f\"      ‚Üí Colonne: {list(X.columns)}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Identificazione tipi di variabili...\")\n",
    "\n",
    "# 2. IDENTIFICAZIONE VARIABILI CATEGORICHE E NUMERICHE\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numeric_features = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(f\"   üìù Variabili CATEGORICHE ({len(categorical_features)}):\")\n",
    "for cat in categorical_features:\n",
    "    valori_unici = X[cat].unique()\n",
    "    print(f\"      ‚Ä¢ {cat}: {valori_unici} ({len(valori_unici)} categorie)\")\n",
    "\n",
    "print(f\"\\n   üî¢ Variabili NUMERICHE ({len(numeric_features)}):\")\n",
    "for num in numeric_features:\n",
    "    range_val = f\"{X[num].min():.1f} - {X[num].max():.1f}\"\n",
    "    print(f\"      ‚Ä¢ {num}: range {range_val}\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Anteprima della separazione...\")\n",
    "print(\"Target (y) - Prime 5 osservazioni:\")\n",
    "print(y.head())\n",
    "\n",
    "print(\"\\nFeatures (X) - Prime 5 righe:\")\n",
    "display(X.head())\n",
    "\n",
    "print(\"\\n‚úÖ Dati preparati per il preprocessing!\")\n",
    "print(f\"   ‚Üí {len(y)} osservazioni\")\n",
    "print(f\"   ‚Üí {len(categorical_features)} variabili categoriche da codificare\")\n",
    "print(f\"   ‚Üí {len(numeric_features)} variabili numeriche da standardizzare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc02ee",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Sezione 5: Creazione Pipeline di Pre-Processing\n",
    "\n",
    "**Cos'√® una Pipeline?**\n",
    "- üîÑ Una **sequenza automatica** di trasformazioni sui dati\n",
    "- üõ°Ô∏è **Evita errori** manuali e garantisce consistenza\n",
    "- üöÄ **Semplifica** il flusso di lavoro\n",
    "- ‚ôªÔ∏è **Riutilizzabile** su nuovi dati\n",
    "\n",
    "### Trasformazioni che applicheremo:\n",
    "\n",
    "**üìù OneHotEncoder** per variabili categoriche:\n",
    "- Trasforma \"Yes\"/\"No\" in colonne binarie (0/1)\n",
    "- `drop='first'` evita ridondanza (problema multicollinearit√†)\n",
    "\n",
    "**üìä StandardScaler** per variabili numeriche:\n",
    "- Porta tutte le variabili a **media=0** e **deviazione standard=1**\n",
    "- Evita che variabili con scale diverse dominino il modello\n",
    "\n",
    "> üí° **Esempio**: Se ho \"Age\" (0-100) e \"Income\" (0-100000), senza scaling l'Income dominerebbe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12067556",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üèóÔ∏è CREAZIONE PIPELINE DI PRE-PROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. CREAZIONE DEL PREPROCESSOR\n",
    "print(\"1Ô∏è‚É£ Configurazione delle trasformazioni...\")\n",
    "\n",
    "# ColumnTransformer: applica trasformazioni diverse a colonne diverse\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Per variabili categoriche: OneHotEncoder\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\", sparse_output=False), categorical_features),\n",
    "        \n",
    "        # Per variabili numeriche: StandardScaler  \n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "    ],\n",
    "    remainder='drop'  # Ignora colonne non specificate\n",
    ")\n",
    "\n",
    "print(\"   üìù OneHotEncoder configurato per variabili categoriche:\")\n",
    "print(f\"      ‚Üí Colonne: {categorical_features}\")\n",
    "print(f\"      ‚Üí drop='first': evita multicollinearit√†\")\n",
    "print(f\"      ‚Üí sparse_output=False: output come array normale\")\n",
    "\n",
    "print(f\"\\n   üìä StandardScaler configurato per variabili numeriche:\")\n",
    "print(f\"      ‚Üí Colonne: {numeric_features}\")\n",
    "print(f\"      ‚Üí Trasforma a media=0, std=1\")\n",
    "\n",
    "# 2. CREAZIONE DELLA PIPELINE COMPLETA\n",
    "print(\"\\n2Ô∏è‚É£ Creazione pipeline completa (preprocessing + modello)...\")\n",
    "\n",
    "# Pipeline: preprocessor + modello di machine learning\n",
    "model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),        # Step 1: Preprocessing\n",
    "    (\"regressor\", LinearRegression())      # Step 2: Modello di regressione\n",
    "])\n",
    "\n",
    "print(\"   üîÑ Pipeline creata con 2 step:\")\n",
    "print(\"      Step 1: Preprocessor (OneHot + Scaling)\")\n",
    "print(\"      Step 2: LinearRegression\")\n",
    "\n",
    "# 3. VISUALIZZAZIONE DELLA PIPELINE\n",
    "print(\"\\n3Ô∏è‚É£ Struttura della pipeline:\")\n",
    "print(f\"   Pipeline(steps=[\")\n",
    "print(f\"       ('preprocessor', ColumnTransformer(...)),\")\n",
    "print(f\"       ('regressor', LinearRegression())\")\n",
    "print(f\"   ])\")\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline di preprocessing creata con successo!\")\n",
    "print(\"\\nüß† Cosa succede quando usiamo la pipeline:\")\n",
    "print(\"   1. I dati passano prima al preprocessor\")\n",
    "print(\"   2. Variabili categoriche ‚Üí OneHot encoding\")\n",
    "print(\"   3. Variabili numeriche ‚Üí Standardizzazione\")\n",
    "print(\"   4. Dati trasformati ‚Üí Modello di regressione\")\n",
    "print(\"   5. Output ‚Üí Previsioni finali\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3417271",
   "metadata": {},
   "source": [
    "## üöÄ Sezione 6: Addestramento e Valutazione del Modello\n",
    "\n",
    "**Perch√© dividere Train/Test?**\n",
    "- üß† **Training Set**: Il modello \"impara\" da questi dati\n",
    "- üß™ **Test Set**: Valutiamo quanto bene il modello generalizza su dati mai visti\n",
    "- üö´ **NO DATA LEAKAGE**: Il test set deve essere completamente ignoto durante l'addestramento\n",
    "\n",
    "### Metriche di Valutazione per la Regressione:\n",
    "\n",
    "**üìä R¬≤ (R-quadrato)**:\n",
    "- Range: 0-1 (pi√π alto = migliore)\n",
    "- Indica **quanto % della varianza** √® spiegata dal modello\n",
    "- R¬≤ = 0.8 ‚Üí Il modello spiega l'80% della variabilit√†\n",
    "\n",
    "**üìè MAE (Mean Absolute Error)**:\n",
    "- Errore medio in **valore assoluto**\n",
    "- Pi√π basso = migliore\n",
    "- Stessa unit√† della variabile target\n",
    "\n",
    "**üéØ RMSE (Root Mean Squared Error)**:\n",
    "- Penalizza di pi√π gli **errori grandi**\n",
    "- Pi√π basso = migliore\n",
    "- Pi√π sensibile agli outlier rispetto al MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f43f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ ADDESTRAMENTO E VALUTAZIONE DEL MODELLO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. DIVISIONE TRAIN/TEST\n",
    "print(\"1Ô∏è‚É£ Divisione del dataset in Training e Test...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,        # 20% per il test, 80% per il training\n",
    "    random_state=42,      # Per risultati riproducibili\n",
    "    stratify=None         # Non necessaria per la regressione\n",
    ")\n",
    "\n",
    "print(f\"   üìö Training Set: {X_train.shape[0]} campioni ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   üß™ Test Set: {X_test.shape[0]} campioni ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   ‚úÖ Divisione completata!\")\n",
    "\n",
    "# 2. ADDESTRAMENTO DEL MODELLO\n",
    "print(\"\\n2Ô∏è‚É£ Addestramento del modello...\")\n",
    "\n",
    "# Addestriamo la pipeline completa sui dati di training\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"   üß† Modello addestrato con successo!\")\n",
    "print(\"   üìä Il modello ha imparato le relazioni tra features e target\")\n",
    "\n",
    "# 3. PREVISIONI\n",
    "print(\"\\n3Ô∏è‚É£ Generazione delle previsioni...\")\n",
    "\n",
    "# Previsioni sui dati di training\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(f\"   üìà Previsioni su Training Set: {len(y_train_pred)} valori\")\n",
    "\n",
    "# Previsioni sui dati di test\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(f\"   üîç Previsioni su Test Set: {len(y_test_pred)} valori\")\n",
    "\n",
    "# 4. CALCOLO DELLE METRICHE\n",
    "print(\"\\n4Ô∏è‚É£ Calcolo metriche di performance...\")\n",
    "\n",
    "# Metriche sul Training Set\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "rmse_train = mean_squared_error(y_train, y_train_pred)**0.5\n",
    "\n",
    "# Metriche sul Test Set  \n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse_test = mean_squared_error(y_test, y_test_pred)**0.5\n",
    "\n",
    "# 5. PRESENTAZIONE DEI RISULTATI\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìä RISULTATI DEL MODELLO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"üèãÔ∏è‚Äç‚ôÇÔ∏è TRAINING SET:\")\n",
    "print(f\"   R¬≤   : {r2_train:.4f} ({r2_train*100:.1f}% della varianza spiegata)\")\n",
    "print(f\"   MAE  : {mae_train:.3f} punti di errore medio\")\n",
    "print(f\"   RMSE : {rmse_train:.3f} punti (penalizza errori grandi)\")\n",
    "\n",
    "print(f\"\\nüß™ TEST SET (performance su dati mai visti):\")\n",
    "print(f\"   R¬≤   : {r2_test:.4f} ({r2_test*100:.1f}% della varianza spiegata)\")\n",
    "print(f\"   MAE  : {mae_test:.3f} punti di errore medio\")\n",
    "print(f\"   RMSE : {rmse_test:.3f} punti (penalizza errori grandi)\")\n",
    "\n",
    "# 6. INTERPRETAZIONE AUTOMATICA\n",
    "print(f\"\\nüéØ INTERPRETAZIONE:\")\n",
    "if abs(r2_train - r2_test) < 0.05:\n",
    "    print(f\"   ‚úÖ Buona generalizzazione (differenza R¬≤ train-test: {abs(r2_train-r2_test):.3f})\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Possibile overfitting (differenza R¬≤ train-test: {abs(r2_train-r2_test):.3f})\")\n",
    "\n",
    "if r2_test > 0.8:\n",
    "    print(f\"   üåü Ottima capacit√† predittiva!\")\n",
    "elif r2_test > 0.6:\n",
    "    print(f\"   üëç Buona capacit√† predittiva\")\n",
    "elif r2_test > 0.4:\n",
    "    print(f\"   ü§î Capacit√† predittiva moderata\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Capacit√† predittiva limitata\")\n",
    "\n",
    "print(f\"   üí° In media sbagliamo di {mae_test:.1f} punti nelle previsioni\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535ce449",
   "metadata": {},
   "source": [
    "## üîç Sezione 7: Analisi dell'Importanza delle Variabili\n",
    "\n",
    "**Cos'√® un Coefficiente nella Regressione Lineare?**\n",
    "\n",
    "La regressione lineare multipla crea un'equazione del tipo:\n",
    "```\n",
    "Performance = Œ≤‚ÇÄ + Œ≤‚ÇÅ√óHours_Studied + Œ≤‚ÇÇ√óPrevious_Scores + Œ≤‚ÇÉ√óSleep_Hours + ...\n",
    "```\n",
    "\n",
    "### Interpretazione dei Coefficienti:\n",
    "\n",
    "**üî¢ Valore del Coefficiente**:\n",
    "- **Positivo** (+): ‚ÜóÔ∏è Se la variabile aumenta, il target aumenta\n",
    "- **Negativo** (-): ‚ÜòÔ∏è Se la variabile aumenta, il target diminuisce\n",
    "- **Vicino a 0**: ü§∑‚Äç‚ôÇÔ∏è La variabile ha poco impatto\n",
    "\n",
    "**üìè Magnitudine (valore assoluto)**:\n",
    "- **Grande**: üí™ Variabile molto influente\n",
    "- **Piccola**: ü§è Variabile poco influente\n",
    "\n",
    "**üè† Intercetta (Œ≤‚ÇÄ)**:\n",
    "- Valore del target quando **tutte le features = 0**\n",
    "\n",
    "> ‚ö†Ô∏è **Attenzione**: I coefficienti sono interpretabili solo se le variabili sono standardizzate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04731dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ ANALISI DELL'IMPORTANZA DELLE VARIABILI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. ESTRAZIONE DEI COEFFICIENTI\n",
    "print(\"1Ô∏è‚É£ Estrazione coefficienti dal modello addestrato...\")\n",
    "\n",
    "# Otteniamo i nomi delle features dopo il preprocessing\n",
    "feature_names = model.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "print(f\"   üìã Numero totale di features dopo preprocessing: {len(feature_names)}\")\n",
    "\n",
    "# Coefficienti del modello di regressione lineare\n",
    "coefficients = model.named_steps[\"regressor\"].coef_\n",
    "print(f\"   üî¢ Numero di coefficienti estratti: {len(coefficients)}\")\n",
    "\n",
    "# Intercetta del modello\n",
    "intercept = model.named_steps[\"regressor\"].intercept_\n",
    "print(f\"   üè† Intercetta del modello: {intercept:.4f}\")\n",
    "\n",
    "# 2. CREAZIONE DATAFRAME PER ANALISI\n",
    "print(\"\\n2Ô∏è‚É£ Organizzazione dei coefficienti...\")\n",
    "\n",
    "# Creiamo un DataFrame per analizzare meglio i coefficienti\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficiente': coefficients,\n",
    "    'Importanza_Assoluta': np.abs(coefficients)  # Valore assoluto per ranking\n",
    "}).sort_values('Importanza_Assoluta', ascending=False)\n",
    "\n",
    "# Puliamo i nomi delle features per renderli pi√π leggibili\n",
    "coef_df['Feature_Pulita'] = coef_df['Feature'].str.replace('cat__', '').str.replace('num__', '')\n",
    "\n",
    "print(f\"   ‚úÖ DataFrame creato e ordinato per importanza\")\n",
    "\n",
    "# 3. TOP VARIABILI PI√ô INFLUENTI\n",
    "print(\"\\n3Ô∏è‚É£ Identificazione delle variabili pi√π influenti...\")\n",
    "\n",
    "print(f\"\\nüèÜ TOP 10 VARIABILI PI√ô INFLUENTI:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Rank':<4} {'Variabile':<25} {'Coefficiente':<12} {'Impatto':<15}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for i, (_, row) in enumerate(coef_df.head(10).iterrows(), 1):\n",
    "    # Determiniamo il tipo di impatto\n",
    "    if row['Coefficiente'] > 0:\n",
    "        impatto = \"‚ÜóÔ∏è Aumenta\"\n",
    "    else:\n",
    "        impatto = \"‚ÜòÔ∏è Diminuisce\"\n",
    "    \n",
    "    print(f\"{i:<4} {row['Feature_Pulita']:<25} {row['Coefficiente']:<12.4f} {impatto}\")\n",
    "\n",
    "# 4. STATISTICHE SUI COEFFICIENTI\n",
    "print(f\"\\nüìä STATISTICHE SUI COEFFICIENTI:\")\n",
    "print(f\"   ‚Ä¢ Coefficiente pi√π alto: {coef_df['Coefficiente'].max():.4f}\")\n",
    "print(f\"   ‚Ä¢ Coefficiente pi√π basso: {coef_df['Coefficiente'].min():.4f}\")\n",
    "print(f\"   ‚Ä¢ Media coefficienti: {coef_df['Coefficiente'].mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ Intercetta: {intercept:.4f}\")\n",
    "\n",
    "# 5. INTERPRETAZIONE BUSINESS\n",
    "print(f\"\\nüíº INTERPRETAZIONE BUSINESS (Top 3 variabili):\")\n",
    "for i, (_, row) in enumerate(coef_df.head(3).iterrows(), 1):\n",
    "    if row['Coefficiente'] > 0:\n",
    "        effect = \"aumenta\"\n",
    "        emoji = \"üìà\"\n",
    "    else:\n",
    "        effect = \"diminuisce\"  \n",
    "        emoji = \"üìâ\"\n",
    "    \n",
    "    print(f\"   {emoji} {row['Feature_Pulita']}: {effect} la performance di {abs(row['Coefficiente']):.3f} punti\")\n",
    "\n",
    "print(f\"\\nüßÆ EQUAZIONE DEL MODELLO (semplificata):\")\n",
    "print(f\"Performance = {intercept:.3f}\", end=\"\")\n",
    "for _, row in coef_df.head(3).iterrows():\n",
    "    sign = \"+\" if row['Coefficiente'] >= 0 else \"\"\n",
    "    print(f\" {sign}{row['Coefficiente']:.3f}√ó{row['Feature_Pulita']}\", end=\"\")\n",
    "print(\" + ...\")\n",
    "\n",
    "print(f\"\\n‚úÖ Analisi dei coefficienti completata!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bef755",
   "metadata": {},
   "source": [
    "## üìä Sezione 8: Visualizzazioni e Diagnosi del Modello\n",
    "\n",
    "**Perch√© Visualizzare i Risultati?**\n",
    "- üëÄ **Vedere √® credere**: I grafici rivelano pattern che i numeri nascondono\n",
    "- üîç **Diagnosticare problemi**: Individuare overfitting, outlier, violazioni assunzioni\n",
    "- üìà **Comunicare risultati**: Presentare in modo comprensibile ai stakeholder\n",
    "\n",
    "### Grafici di Diagnosi che Creeremo:\n",
    "\n",
    "**1. üéØ Scatter Plot: Valori Reali vs Predetti**\n",
    "- Punti vicini alla linea diagonale = buone previsioni\n",
    "- Punti sparsi = previsioni imprecise\n",
    "\n",
    "**2. üìâ Grafico dei Residui**\n",
    "- Residui = Differenza tra valori reali e predetti\n",
    "- Pattern casuali = modello buono\n",
    "- Pattern sistematici = problemi nel modello\n",
    "\n",
    "**3. üìä Importanza delle Variabili**\n",
    "- Bar chart dei coefficienti pi√π importanti\n",
    "- Visualizza quale variabile ha pi√π peso\n",
    "\n",
    "**4. üìã Distribuzione degli Errori**\n",
    "- Istogramma dei residui\n",
    "- Dovrebbe assomigliare a una distribuzione normale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä VISUALIZZAZIONI E DIAGNOSI DEL MODELLO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Creiamo una figura con 4 sottografici per la diagnosi del modello\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('üîç Diagnosi del Modello di Regressione Lineare Multipla', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Calcoliamo i residui per l'analisi\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# 1. GRAFICO: VALORI REALI vs PREDETTI\n",
    "axes[0,0].scatter(y_test, y_test_pred, alpha=0.6, color='blue', s=50)\n",
    "# Linea perfetta (previsioni = valori reali)\n",
    "min_val, max_val = y.min(), y.max()\n",
    "axes[0,0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=3, label='Previsione Perfetta')\n",
    "axes[0,0].set_xlabel('Valori Reali (Performance Index)', fontsize=12)\n",
    "axes[0,0].set_ylabel('Valori Predetti', fontsize=12)\n",
    "axes[0,0].set_title('üéØ Valori Reali vs Predetti', fontsize=14, fontweight='bold')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Aggiungiamo l'R¬≤ nel grafico\n",
    "axes[0,0].text(0.05, 0.95, f'R¬≤ = {r2_test:.3f}', transform=axes[0,0].transAxes, \n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
    "               fontsize=12, fontweight='bold')\n",
    "\n",
    "# 2. GRAFICO: RESIDUI vs VALORI PREDETTI\n",
    "axes[0,1].scatter(y_test_pred, residuals, alpha=0.6, color='green', s=50)\n",
    "axes[0,1].axhline(y=0, color='red', linestyle='--', linewidth=2, label='Residui = 0')\n",
    "axes[0,1].set_xlabel('Valori Predetti', fontsize=12)\n",
    "axes[0,1].set_ylabel('Residui (Reale - Predetto)', fontsize=12)\n",
    "axes[0,1].set_title('üìâ Grafico dei Residui', fontsize=14, fontweight='bold')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,1].legend()\n",
    "\n",
    "# 3. GRAFICO: IMPORTANZA DELLE VARIABILI (TOP 8)\n",
    "top_features = coef_df.head(8)\n",
    "colors = ['red' if coef < 0 else 'blue' for coef in top_features['Coefficiente']]\n",
    "bars = axes[1,0].barh(range(len(top_features)), top_features['Coefficiente'], color=colors, alpha=0.7)\n",
    "axes[1,0].set_yticks(range(len(top_features)))\n",
    "axes[1,0].set_yticklabels(top_features['Feature_Pulita'], fontsize=10)\n",
    "axes[1,0].set_xlabel('Coefficiente', fontsize=12)\n",
    "axes[1,0].set_title('üìä Top 8 Coefficienti del Modello', fontsize=14, fontweight='bold')\n",
    "axes[1,0].grid(True, alpha=0.3, axis='x')\n",
    "axes[1,0].axvline(x=0, color='black', linewidth=1)\n",
    "\n",
    "# Aggiungiamo i valori sulle barre\n",
    "for i, (bar, coef) in enumerate(zip(bars, top_features['Coefficiente'])):\n",
    "    width = bar.get_width()\n",
    "    label_x = width + 0.01 if width >= 0 else width - 0.01\n",
    "    ha = 'left' if width >= 0 else 'right'\n",
    "    axes[1,0].text(label_x, bar.get_y() + bar.get_height()/2, f'{coef:.3f}', \n",
    "                   ha=ha, va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# 4. GRAFICO: DISTRIBUZIONE DEI RESIDUI\n",
    "axes[1,1].hist(residuals, bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
    "axes[1,1].set_xlabel('Residui', fontsize=12)\n",
    "axes[1,1].set_ylabel('Frequenza', fontsize=12)\n",
    "axes[1,1].set_title('üìã Distribuzione dei Residui', fontsize=14, fontweight='bold')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Aggiungiamo statistiche sui residui\n",
    "mean_residuals = np.mean(residuals)\n",
    "std_residuals = np.std(residuals)\n",
    "axes[1,1].axvline(mean_residuals, color='red', linestyle='--', linewidth=2, \n",
    "                  label=f'Media: {mean_residuals:.3f}')\n",
    "axes[1,1].text(0.05, 0.95, f'Std: {std_residuals:.3f}', transform=axes[1,1].transAxes,\n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7),\n",
    "               fontsize=10)\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# INTERPRETAZIONE DEI GRAFICI\n",
    "print(\"\\nüîç INTERPRETAZIONE DEI GRAFICI:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"üìä GRAFICO 1 - Valori Reali vs Predetti:\")\n",
    "if r2_test > 0.8:\n",
    "    print(f\"   ‚úÖ Punti molto vicini alla linea rossa = ottime previsioni\")\n",
    "elif r2_test > 0.6:\n",
    "    print(f\"   üëç Buona distribuzione attorno alla linea rossa\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Punti sparsi = previsioni poco accurate\")\n",
    "\n",
    "print(f\"\\nüìâ GRAFICO 2 - Residui:\")\n",
    "if abs(np.mean(residuals)) < 0.5:\n",
    "    print(f\"   ‚úÖ Residui centrati sullo zero = nessun bias sistematico\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Residui non centrati = possibile bias nel modello\")\n",
    "\n",
    "print(f\"\\nüìä GRAFICO 3 - Importanza Variabili:\")\n",
    "top_var = coef_df.iloc[0]['Feature_Pulita']\n",
    "print(f\"   üèÜ Variabile pi√π importante: {top_var}\")\n",
    "print(f\"   üìà Coefficienti positivi (blu) aumentano la performance\")\n",
    "print(f\"   üìâ Coefficienti negativi (rossi) diminuiscono la performance\")\n",
    "\n",
    "print(f\"\\nüìã GRAFICO 4 - Distribuzione Residui:\")\n",
    "if abs(mean_residuals) < std_residuals/3:\n",
    "    print(f\"   ‚úÖ Distribuzione simmetrica = assunzioni del modello rispettate\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Distribuzione asimmetrica = possibili violazioni assunzioni\")\n",
    "\n",
    "print(f\"\\nüìù RIASSUNTO DIAGNOSTICO:\")\n",
    "print(f\"   ‚Ä¢ Media residui: {mean_residuals:.3f} (dovrebbe essere ~0)\")\n",
    "print(f\"   ‚Ä¢ Std residui: {std_residuals:.3f}\")\n",
    "print(f\"   ‚Ä¢ R¬≤ test: {r2_test:.3f}\")\n",
    "print(f\"   ‚Ä¢ Modello {'adeguato' if r2_test > 0.6 else 'da migliorare'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffca551",
   "metadata": {},
   "source": [
    "## üéì Conclusioni e Riassunto della Lezione\n",
    "\n",
    "### üìã Cosa Abbiamo Imparato:\n",
    "\n",
    "**1. üîç Analisi Esplorativa dei Dati**\n",
    "- Come esplorare e comprendere un dataset\n",
    "- Identificare correlazioni tra variabili\n",
    "- Visualizzare distribuzioni e relazioni\n",
    "\n",
    "**2. üõ†Ô∏è Preprocessing dei Dati**\n",
    "- Separare target e features\n",
    "- Gestire variabili categoriche (OneHot Encoding)\n",
    "- Standardizzare variabili numeriche (StandardScaler)\n",
    "\n",
    "**3. üöÄ Machine Learning Pipeline**\n",
    "- Costruire una pipeline automatica\n",
    "- Dividere dati in train/test\n",
    "- Addestrare un modello di regressione lineare multipla\n",
    "\n",
    "**4. üìä Valutazione del Modello**\n",
    "- Metriche: R¬≤, MAE, RMSE\n",
    "- Interpretare la bont√† delle previsioni\n",
    "- Riconoscere overfitting\n",
    "\n",
    "**5. üî¨ Interpretazione dei Risultati**\n",
    "- Analizzare coefficienti e loro significato\n",
    "- Identificare variabili pi√π importanti\n",
    "- Diagnosticare il modello con visualizzazioni\n",
    "\n",
    "### üß† Concetti Chiave da Ricordare:\n",
    "\n",
    "> **Regressione Lineare Multipla**: Prevede valori continui usando pi√π variabili predittive\n",
    "\n",
    "> **Pipeline**: Automatizza preprocessing e modelling per evitare errori\n",
    "\n",
    "> **Train/Test Split**: Essenziale per valutare la capacit√† di generalizzazione\n",
    "\n",
    "> **Coefficienti**: Indicano l'impatto di ogni variabile sulla previsione\n",
    "\n",
    "### üöÄ Prossimi Passi:\n",
    "\n",
    "- **Migliorare il modello**: Feature engineering, polinomiali, regolarizzazione\n",
    "- **Altri algoritmi**: Random Forest, SVM, Neural Networks\n",
    "- **Validazione robusta**: Cross-validation, metriche multiple\n",
    "- **Deploy**: Portare il modello in produzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ ESEMPIO PRATICO: Previsione per un Nuovo Studente\n",
    "print(\"=\"*60)\n",
    "print(\"üéØ ESEMPIO PRATICO: PREVISIONE PER UN NUOVO STUDENTE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Creiamo un esempio di nuovo studente\n",
    "nuovo_studente = pd.DataFrame({\n",
    "    'Hours Studied': [7],                        # 7 ore di studio al giorno\n",
    "    'Previous Scores': [85],                     # Punteggio precedente 85/100\n",
    "    'Extracurricular Activities': ['Yes'],       # Partecipa ad attivit√† extra\n",
    "    'Sleep Hours': [8],                          # 8 ore di sonno\n",
    "    'Sample Question Papers Practiced': [5]      # Ha fatto 5 test di pratica\n",
    "})\n",
    "\n",
    "print(\"üìù Caratteristiche del nuovo studente:\")\n",
    "display(nuovo_studente)\n",
    "\n",
    "# Facciamo la previsione\n",
    "previsione = model.predict(nuovo_studente)\n",
    "\n",
    "print(f\"\\nüîÆ PREVISIONE DEL MODELLO:\")\n",
    "print(f\"   Performance Index prevista: {previsione[0]:.2f}/100\")\n",
    "\n",
    "# Calcoliamo un intervallo di confidenza approssimativo\n",
    "intervallo = rmse_test * 1.96  # ~95% di confidenza\n",
    "print(f\"   Intervallo di confidenza (~95%): {previsione[0]-intervallo:.1f} - {previsione[0]+intervallo:.1f}\")\n",
    "\n",
    "# Interpretazione\n",
    "if previsione[0] >= 90:\n",
    "    performance_level = \"üåü Eccellente\"\n",
    "elif previsione[0] >= 80:\n",
    "    performance_level = \"üëç Molto Buona\"\n",
    "elif previsione[0] >= 70:\n",
    "    performance_level = \"‚úÖ Buona\"\n",
    "elif previsione[0] >= 60:\n",
    "    performance_level = \"ü§î Sufficiente\"\n",
    "else:\n",
    "    performance_level = \"‚ùå Da Migliorare\"\n",
    "\n",
    "print(f\"   Livello di performance: {performance_level}\")\n",
    "\n",
    "print(f\"\\n‚úÖ ESERCIZIO COMPLETATO CON SUCCESSO!\")\n",
    "print(f\"Hai imparato a costruire e utilizzare un modello di regressione lineare multipla!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
